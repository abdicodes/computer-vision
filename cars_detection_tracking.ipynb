{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build A Motion Detected Alarm System with Python and OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we are going to develop – again! – a motion triggered alarm based on the frame differencing method. Now, we are going to do this using Python and OpenCV.\n",
    "\n",
    "Open Source Computer Vision Library (OpenCV) is a library written in C/C++ mainly aimed at real-time computer vision.\n",
    "\n",
    "OpenCV supports a wide variety of programming languages such as C++, Python, Java, etc. \n",
    "\n",
    "In particular, in this exercise we are going to introduce OpenCV-Python, a Python wrapper for the original OpenCV C++ implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach for developing this application is the same as proposed in Exercise 14:\n",
    "\n",
    "When the program starts, the program will capture from the webcam the ‘baseline’ image (see the left image below). This is the image without any 'intruder'. The program will keep capturing frames and comparing them with the baseline image. If no one enters the frame, nothing will happen. However, when somebody or something enters the frame (see the right image below), the program will detect that the captured frame and the baseline image are ‘very’ different and will trigger the audio alarm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alarm](../Images/Alarm_v2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very important: you need to run the code in your local machine for displaying the video and using the webcam.**\n",
    "\n",
    "**Exercise 1.1**: Download (or copy) this Jupyter notebook into your local machine.\n",
    "\n",
    "**Exercise 1.2**: Install the required Python libraries\n",
    "\n",
    "                pip install pyttsx3\n",
    "                pip install pywin32\n",
    "                pip install numpy\n",
    "                pip install opencv-python\n",
    "\n",
    "**Exercise 1.3**: Run and study the code *Capture and display the frames of a video with Python and OpenCV*.\n",
    "\n",
    "**Exercise 1.4**: Run and study the code *Capture and display webcam with Python and OpenCV*.\n",
    "\n",
    "**Exercise 1.5**: Run and study the code *Build a motion detected alarm system with Python*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3. Capture and display the frames of a video with Python and OpenCV.\n",
    "\n",
    " Run and study the code Capture and display the frames of a video with Python and OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyttsx3\n",
    "!pip install pywin32\n",
    "!pip install numpy\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This lab is based on https://github.com/arindomjit/Motion_Detected_Alarm by Arindomjit Bhattacharjee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c4590ba90180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mbg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('../../Downloads//Exercise1_Files/Traffic_Laramie_1.mp4')\n",
    "\n",
    "# Create background subtractor object\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Capture the first frame and use it as the background image\n",
    "_, bg = cap.read()\n",
    "height, width , _ = bg.shape\n",
    "bg = cv2.cvtColor(bg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "bg = bg[int(height/2): height, 0:width]\n",
    "\n",
    "\n",
    "# Initialize list to hold trackers for each car\n",
    "trackers = []\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    height, width , _ = frame.shape\n",
    "    main_street = frame[int(height/2): height, 0:width]\n",
    "    \n",
    "    # Convert the current frame to grayscale\n",
    "    gray = cv2.cvtColor(main_street, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # Perform background subtraction to obtain the foreground mask\n",
    "    fgmask = fgbg.apply(gray)\n",
    "\n",
    "    # Perform frame differencing to obtain the difference mask\n",
    "    diff = cv2.absdiff(gray, bg)\n",
    "\n",
    "    # Combine the foreground mask and the difference mask to get the final mask\n",
    "    mask = cv2.bitwise_and(fgmask, diff)\n",
    "\n",
    "    # Apply morphological operations to improve mask quality\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "#     mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Find contours in the final mask\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Loop over the contours to filter the cars and create bounding boxes\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < 2000:\n",
    "            continue\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = w * h\n",
    "        aspect_ratio = w / h\n",
    "        if area > 7000 and aspect_ratio > 0.3 and aspect_ratio < 3:\n",
    "\n",
    "\n",
    "#         (x, y, w, h)=cv2.boundingRect(c)\n",
    "            cv2.rectangle(frame, (x, y + int(height/2)), (x+w, y+h + int(height/2)), (0,255,0), 1)\n",
    "\n",
    "#         # Filter based on size, aspect ratio, and position\n",
    "#         if area > 500 and aspect_ratio > 0.3 and aspect_ratio < 3 and y > 100 and y < 400:\n",
    "#             # Initialize a new tracker for the car\n",
    "#             tracker = cv2.TrackerCSRT_create()\n",
    "#             tracker.init(frame, (x, y, w, h))\n",
    "#             trackers.append(tracker)\n",
    "\n",
    "    # Update the tracker for each car and draw the bounding box\n",
    "#     for tracker in trackers:\n",
    "#         ok, bbox = tracker.update(frame)\n",
    "#         if ok:\n",
    "#             x, y, w, h = [int(v) for v in bbox]\n",
    "#             cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.imshow('Mask', mask)\n",
    "    cv2.imshow('Main street', main_street)\n",
    "\n",
    "    # Update the background image for the next frame\n",
    "    bg = gray\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# traffic counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car passed\n",
      "car passed\n",
      "car passed\n",
      "car passed\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'destroyAllWindos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-24a80975bcbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'destroyAllWindos'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('../../Downloads//Exercise1_Files/Traffic_Laramie_2.mp4')\n",
    "\n",
    "# Create background subtractor object\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Capture the first frame and use it as the background image\n",
    "_, bg = cap.read()\n",
    "height, width , _ = bg.shape\n",
    "\n",
    "x_offset = 150\n",
    "y_offset = 170\n",
    "x_start_point = int(width/2) - x_offset\n",
    "x_end_point = int(width/2 )\n",
    "y_start_point = int(height/2)\n",
    "y_end_point = int(height/2) + y_offset\n",
    "bg = cv2.cvtColor(bg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "bg = bg[y_start_point: y_end_point,x_start_point:x_end_point]\n",
    "\n",
    "prev_loc = []\n",
    "curr_loc = []\n",
    "count = 0 \n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    height, width , _ = frame.shape\n",
    "    city_center_street = frame[int(height/2): (int(height/2) + y_offset), int(width/2) - x_offset:int(width/2 )]\n",
    "    \n",
    "    # Convert the current frame to grayscale\n",
    "    gray = cv2.cvtColor(city_center_street, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform background subtraction to obtain the foreground mask\n",
    "    fgmask = fgbg.apply(gray)\n",
    "\n",
    "    # Perform frame differencing to obtain the difference mask\n",
    "    diff = cv2.absdiff(gray, bg)\n",
    "\n",
    "    # Combine the foreground mask and the difference mask to get the final mask\n",
    "    mask = cv2.bitwise_and(fgmask, diff)\n",
    "\n",
    "    # Find contours in the final mask\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    curr_loc = []\n",
    "    x = y = w = h= 0\n",
    "   \n",
    "\n",
    "    # Loop over the contours to filter the cars and create bounding boxes\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) < 2000:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "       \n",
    "        area = w * h\n",
    "        aspect_ratio = w / h\n",
    "        if area > 6500 and aspect_ratio > 0.3 and aspect_ratio < 3:\n",
    "\n",
    "            x=  x + x_start_point\n",
    "            y = y + y_start_point\n",
    "           \n",
    "            cv2.rectangle(frame, (x, y ), (x+w, y+h), (0,255,0), 1)\n",
    "            curr_loc.extend((x,y))\n",
    "            \n",
    "    if len(prev_loc) > 0 and len(curr_loc) == 0:\n",
    "        print('car passed')\n",
    "        count+=1\n",
    "\n",
    "\n",
    "           \n",
    "    cv2.rectangle(frame, (int((x_start_point + x_end_point)/2), y_start_point  ), (int((x_start_point + x_end_point)/2), y_end_point), (0,255,0), 1)\n",
    "    # Show the result\n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.imshow(' Counting point', city_center_street)\n",
    "    cv2.putText(frame, f\"Cars passed: {count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Update the background image for the next frame\n",
    "    bg = gray\n",
    "    prev_loc = curr_loc.copy()\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindos()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
